{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "Before we jump in to file I/O functions, lets first look at some basic I/O functions that are available to use in Python. \n",
    "In Python, there are three basic I/O connections, Standard Input, Standard Output and Standard Error. As the name suggests, Standard Input is the data that goes to the program through the keyboard. keyboard being the standard input. Standard output is the terminal console, unless redirected..(guess where?!!) and Standard error is the stream where the programs write their error messages which is again to the terminal unless redirected.\n",
    "\n",
    "### Standard Input, Output and Error:\n",
    "\n",
    "The `input( )` function reads one line from the standard input and returns it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name: aasf\n",
      "Hello aasf\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Enter your name: \")\n",
    "print(\"Hello {name}\".format(name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter something: asdfasdf\n",
      "You entered: asdfasdf\n"
     ]
    }
   ],
   "source": [
    "# Lets use list comprehension in the input\n",
    "some_val = input(\"Enter something: \")\n",
    "print(\"You entered: {}\".format(some_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python2 users would have observed the output as `You entered: [0, 2, 4, 6, 8]`\n",
    "and Python3 users would have observed the output as `[x for x in range(10) if x%2 == 0]`\n",
    "\n",
    "Until Python3.2 there used to be two methods for accepting input -- `raw_input` and `input` the behavior that python3 users are seeing is the actual behavior of `raw_input`. However after Python3.2, it was decided to drop the `input` method.\n",
    "> For the sake of staying on topic, we cannot discuss more on this.. but for the curious souls.. head here: https://www.python.org/dev/peps/pep-3111/\n",
    "\n",
    "We saw the Standard Error in the Exception Handling module. \n",
    "\n",
    "We've also been using Standard Output since `module 1`, I guess.. using the `print` function (for python3) or `print` statement (for python2), right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File I/O\n",
    "Until now you have been reading and writing to the standard input. Lets now perform the same function to the files. Now we will see how we can read and write to the files.\n",
    "\n",
    "#### Opening Files: \n",
    "Files can be opened using python's built-in `open()` function. This function creates a file object which is used for performing different operations on the file. It will become much clear when we look at a complete example. For now, just remember that we need to create a file object before performing any file I/O and try to remember the syntax.\n",
    "`fhandler = open(file_name, access mode, encoding)`\n",
    "\n",
    "- `file_name`: The file name that you would like to perform your I/O operations on.\n",
    "- `encoding`: Encoding tells python what encoding scheme to use to convert the stream of bytes to text. \n",
    "- `access_mode`: This is the mode which determines if the file is to opened as read only,read-write, write only etc modes. The ways in which a file can be opened are mentioned below:\n",
    "\n",
    "|access_mode | Its Function|\n",
    "|:------|------------:|\n",
    "|r\t|Opens a file as read only|\n",
    "|rb\t|Opens a file as read only in binary format|\n",
    "|r+\t|Opens a file for reading and writing|\n",
    "|rb+\t|Opens a file for reading and writing in binary format|\n",
    "|w\t|Opens a file for writing only|\n",
    "|wb\t|Opens a file for writing only in binary format|\n",
    "|w+\t|Opens a file for both reading and writing|\n",
    "|wb+\t|Opens a file for writing and reading in binary format|\n",
    "|a\t|Opens a file for appending|\n",
    "|ab\t|Opens a file for appending in binary|\n",
    "|a+\t|Opens a file for appending and reading|\n",
    "|ab+\t|Opens a file for appending and reading in binary format|\n",
    "\n",
    "#### Reading and Writing\n",
    "Once we have created a file object we can perform many operations on the file object which, like all objects, has methods to take care of nitty gritty details and perform the operations on the file. Before we jump into the functions, lets take a look at a complete File I/O example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fhandler = open('test.txt', 'w') \n",
    "    fhandler.write('Hello World')\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)\n",
    "finally:\n",
    "    if fhandler:\n",
    "        fhandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above code ran without any exception, then it should have created a file test.txt (and if it existed before, it will overwrite it because of access_mode as `w`)\n",
    "\n",
    "Now before we proceed ahead, don't you think the total number of lines that we wrote to achieve just a small objective (of writing a string to file) is too much effort?\n",
    "\n",
    "Let's look at an alternative way of writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('test.txt', 'w') as fhandler:\n",
    "        fhandler.write('Hello World')\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, eh?\n",
    "\n",
    "In fact, It is good practice to use the `with` keyword when dealing with file objects. This has the advantage that the file is properly closed (`fhandler.close()`) after its suite finishes, even if an exception is raised on the way. It is also much shorter than writing equivalent `try-except-finally` blocks.\n",
    "\n",
    "Want another reason for using `with` statement? Ok, if you want to open multiple files together, you can do that using with statement by simply separating the different file handlers by a comma.. \n",
    "something like this\n",
    "```\n",
    "with open('test0.txt', 'w') as fh0, open('test1.txt', 'w') as fh1 ...\n",
    "```\n",
    "\n",
    "So what is `with` statement? Putting it very very simply.. `with` has `__enter__()` and `__exit__()` functions where stuff like opening and closing the file handler can take place. The `with` statement guarantees that if the `__enter__()` method returns without an error, then `__exit__()` will always be called.\n",
    "\n",
    "> We cannot discuss more about `with` statement here--it can take up a whole module--but again for curious minds out there, read this `pep`: https://www.python.org/dev/peps/pep-0343/\n",
    "\n",
    "Alright, coming back to our discussion on File I/O,  lets now look at some of the functions that you may end up using.\n",
    "\n",
    "##### file_object.close()\n",
    "\n",
    "This method will close the file that we have currently open. You should always call this method once you are done performing I/O operations on the file using the file object unless you are using `with` statement. `with` statement already does that for you.\n",
    "\n",
    "#####  file_object.mode\n",
    "\n",
    "This is a read-only attribute that is the value of the mode string used in the open call that created the file_object\n",
    "\n",
    "##### file_object.readline([size])\n",
    "\n",
    "This method reads strings from the file till it reaches new line character ( `\\n` ) if the `size` parameter is empty. If an integer is provided as size parameter, then this method returns string of length size.\n",
    "\n",
    "##### file_object.readlines([size])\n",
    "\n",
    "This method basically calls the `readline()` method till it reaches the end of file.\n",
    "\n",
    "##### file_object.seek(pos, how=0)\n",
    "\n",
    "Sets the file_object's current position to the signed integer byte offset by pos from the reference point. The how parameter, which is 0 by default, indicates the reference point. `how`=1 is the reference of current position and `how`=2 is the reference of the end of the file.\n",
    "\n",
    "##### file_object.tell()\n",
    "\n",
    "This method tells the current file position when you are reading from or writing to a file.\n",
    "\n",
    "##### file_object.truncate([size])\n",
    "\n",
    "This method truncates the file to be at most of size size.  If you don't mention the size it takes the size from `tell()` method as the new size.\n",
    "\n",
    "##### file_object.write(str)\n",
    "\n",
    "Writes the bytes of string str to the file.\n",
    "\n",
    "##### file_object.writelines(lst)\n",
    "\n",
    "Writes sequence of strings to file. No new line is added automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "['Hello World.This is Python']\n",
      "After truncate:  ['Hello World.This is ']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('test.txt', 'r+') as fhandler:\n",
    "        print(fhandler.readline())\n",
    "        fhandler.writelines(['.', 'This is', ' Python'])\n",
    "        # Go to the starting of file\n",
    "        fhandler.seek(0)\n",
    "        # Print the content of file\n",
    "        print(fhandler.readlines())\n",
    "        fhandler.truncate(20)\n",
    "        fhandler.seek(0)\n",
    "        print('After truncate: ',fhandler.readlines())\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we opened the file, read its contents, added multiple strings, truncated and closed it! This covers pretty much everything that you will need when you are working with almost any kind of file that has some text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 - 06.03 CSV File I/O\n",
    "In the above examples, we saw how to perform read-write operations on a file. This is generally used for files that have multiple lines of strings. However if you have data like this:\n",
    "\n",
    "||||\n",
    "|:--|:--|:--|\n",
    "|Data1\t|Data2\t|Data3|\n",
    "|Example1\t|Example2\t|Example3|\n",
    "\n",
    "It is stored in a file with this format:\n",
    "```\n",
    "Data1, Data2, Data3\n",
    "Example01, Example02, Example03\n",
    "Example11, Example12, Example13\n",
    "```\n",
    "\n",
    "As can be seen in the above example, each row is a new line, and each column is separated with a comma. Many online services allow its users to export tabular data from the website into a CSV file. These files can then be opened and viewed offline using a Spreadsheet program such as Google Sheets, Numbers or Microsoft Excel.\n",
    "\n",
    ">Disclaimer: The data generated is completely random using a third party website [`https://www.fakenamegenerator.com`](https://www.fakenamegenerator.com 'FakeName Generator')\n",
    "\n",
    "\n",
    "#### So why do we need such CSV files? \n",
    "There are two primary reasons for the existence of this format:\n",
    "\n",
    "- CSV are plain-text files which makes them easy to store and read from\n",
    "- CSV files are stored as sequence of human readable characters, thus making it easy for humans to interpret the data without requiring any format conversion.\n",
    "- CSV is a delimited text file that uses a comma to separate values (many implementations of CSV import/export tools allow other separators to be used). Simple CSV implementations may prohibit field values that contain a comma or other special characters such as newlines. More sophisticated CSV implementations permit them, often by requiring \" (double quote) characters around values that contain reserved characters (such as commas, double quotes, or less commonly, newlines). Embedded double quote characters may then be represented by a pair of consecutive double quotes, or by prefixing an escape character such as a backslash (for example in Sybase Central). The name \"CSV\" indicates the use of the comma to separate data fields. Nevertheless, the term \"CSV\" is widely used to refer a large family of formats, which differ in many ways. Some implementations allow or require single or double quotation marks around some or all fields; and some reserve the very first record as a header containing a list of field names. An official standard for the CSV file format does not exist.\n",
    "\n",
    "Download a Sample\\* CSV file from [`HERE`](./sample_datasets/sample_names.csv 'Sample CSV') and save it in your current folder location. \n",
    "\n",
    "\n",
    "#### Reading CSV files\n",
    "\n",
    "`reader()` can be used to create an object that is used to read the data from a csv file. The reader can be used as an iterator to process the rows of the file in order. Lets take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\ufeffGivenName', 'Gender', 'Title', 'Occupation', 'City'], ['Nicholas', 'male', 'Mr.', 'Speech writer', 'Plantation'], ['Jeanette', 'female', 'Mrs.', 'Surfacing equipment operator', 'Chicago'], ['David', 'male', 'Mr.', 'Engineering geologist', 'Worthington'], ['Susan', 'female', 'Ms.', 'Cutting, punching, and press machine tender', 'Fulton'], ['Dennis', 'male', 'Mr.', 'Construction millwright', 'Fargo'], ['Susan', 'female', 'Mrs.', 'Private investigator', 'Blackwood'], ['John', 'male', 'Mr.', 'Chemical engineering technician', 'Marietta'], ['Damon', 'male', 'Mr.', 'Loan closer', 'Mansfield'], ['George', 'male', 'Mr.', 'Public defender', 'Minneapolis']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "row = []\n",
    "try:\n",
    "    with open('./sample_datasets/sample_names.csv', 'r') as fh:\n",
    "        reader = csv.reader(fh)\n",
    "        for info in reader:\n",
    "            row.append(info)\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)\n",
    "\n",
    "print(row[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reader()` is a method available in csv package so the first line basically imports the csv package. The `reader()` method takes sequence or an iterable file object, and returns an iterator. As the csv file is being read, each row of the input data is converted to a list of strings. The parser handles the line breaks embedded within the strings which is why using row is not always the output that you might get when taking a line input from file. \n",
    "\n",
    "#### Writing CSV files\n",
    "\n",
    "Writing csv files is just as easy as reading them. To write to a csv file, we can use `writer()` method to create an object for writing and then iterate over the rows using csv's `writerow()` method to write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "try:\n",
    "    with open('test.csv', 'w') as fh:\n",
    "        writer = csv.writer(fh)\n",
    "        for num in range(10):\n",
    "            writer.writerow((num, num**1, num**2))\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try opening the file just like we did before and see the contents\n",
    "\n",
    "#### DictReader\n",
    "\n",
    "In addition to working with sequences or data, the `csv` module includes classes for working with rows as dictionaries so that the fields can be named. The `DictReader` and `DictWriter` classes translate rows to dictionaries instead of lists. Keys for the dictionary can be passed in, or inferred from the first row in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('\\ufeffGivenName', 'Nicholas'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Speech writer'), ('City', 'Plantation')]), OrderedDict([('\\ufeffGivenName', 'Jeanette'), ('Gender', 'female'), ('Title', 'Mrs.'), ('Occupation', 'Surfacing equipment operator'), ('City', 'Chicago')]), OrderedDict([('\\ufeffGivenName', 'David'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Engineering geologist'), ('City', 'Worthington')]), OrderedDict([('\\ufeffGivenName', 'Susan'), ('Gender', 'female'), ('Title', 'Ms.'), ('Occupation', 'Cutting, punching, and press machine tender'), ('City', 'Fulton')]), OrderedDict([('\\ufeffGivenName', 'Dennis'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Construction millwright'), ('City', 'Fargo')]), OrderedDict([('\\ufeffGivenName', 'Susan'), ('Gender', 'female'), ('Title', 'Mrs.'), ('Occupation', 'Private investigator'), ('City', 'Blackwood')]), OrderedDict([('\\ufeffGivenName', 'John'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Chemical engineering technician'), ('City', 'Marietta')]), OrderedDict([('\\ufeffGivenName', 'Damon'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Loan closer'), ('City', 'Mansfield')]), OrderedDict([('\\ufeffGivenName', 'George'), ('Gender', 'male'), ('Title', 'Mr.'), ('Occupation', 'Public defender'), ('City', 'Minneapolis')]), OrderedDict([('\\ufeffGivenName', 'Elizabeth'), ('Gender', 'female'), ('Title', 'Dr.'), ('Occupation', 'Professional athlete'), ('City', 'Boston')])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "row = []\n",
    "try:\n",
    "    with open('./sample_datasets/sample_names.csv', 'r') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        for info in reader:\n",
    "            row.append(info)\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)\n",
    "\n",
    "print(row[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Python 2 users should see a `list of dictionaries` and Python3 users should see a list of `OrderedDict`. The `OrderedDict`, as the name suggests, will preserve the order in which the entries were inserted. (You can guess why!)\n",
    "\n",
    "#### DictWriter\n",
    "\n",
    "Similar to DictReader, we also have DictWriter which needs to be given a list of field names so it knows how to order the columns in the output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "try:\n",
    "    fieldnm = ('Title1', 'Title2', 'Title3')\n",
    "    with open('test_dict.csv', 'w') as fh:\n",
    "        writer = csv.DictWriter(fh, fieldnames=fieldnm)\n",
    "        headers = dict((hdr, hdr) for hdr in fieldnm)\n",
    "        for num in range(10):\n",
    "            writer.writerow({'Title1':num, 'Title2':num+1, 'Title3':num+2})\n",
    "except IOError as ex:\n",
    "    print(\"Error performing I/O operations on the file: \",ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above DictReader and DictWriter techniques are good when the filesize (or the number of columns) is not very big. When the row numbers start scaling up, the list that is created by the reader() method starts growing in memory and makes the process very very slow. \n",
    "\n",
    "We will generally be dealing with the files that have over a million row entries and this method is not the most efficient way of dealing with such files. To handle such 'Big Data', we will study python packages like `Numpy` and `Pandas` in next few modules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
